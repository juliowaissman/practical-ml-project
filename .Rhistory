f.rating(2)
f.rating(0)
f.rating(-200)
f.rating(523)
f.rating(-523)
f.rating(-750)
f.rating(-120)
f.rating(-125)
f.rating <- function (x){round(1 / (1 + 10^(x/400)), 2)}
f.rating(-125)
f.rating(-120)
f.rating <- function (x){truncate(1 / (1 + 10^(x/400)), 2)}
f.rating(-120)
?round
f.rating <- function (x){trunc(1 / (1 + 10^(x/400)), 2)}
f.rating(-120)
f.rating <- function (x){signif(1 / (1 + 10^(x/400)), 2)}
f.rating(-120)
f.rating <- function (x){floor(1 / (1 + 10^(x/400)), 2)}
f.rating(-120)
f.rating <- function (x){1 / (1 + 10^(x/400))}
f.rating(-120)
f.rating(-121)
f.rating(-122)
f.rating(-123)
library(knitr)
library(dplyr)     #  Manipulación de datos
library(reshape2)  #  Manipulación de datos
library(ggplot2)   # Graficación
library(lubridate) # Manejo de fechas y hora
data.dir <- "./raw_data/data_sep_2016/"
archivo.junto <- "todo_junto.csv.gz"
ejercicios.df <- read.csv(gzfile(paste(data.dir, archivo.junto, sep = "")))
ejercicios.df$FechaRegistro <- ymd_hms(ejercicios.df$FechaRegistro)
ejercicios.df$IdEjercicio <- factor(ejercicios.df$IdEjercicio)
ejercicios.df$IdPlantilla <- factor(ejercicios.df$IdPlantilla)
num.conceptos <- length(levels(ejercicios.df$IdConcepto))
ejercicios.df$IdConceptoCorto <- ejercicios.df$IdConcepto
levels(ejercicios.df$IdConceptoCorto) <- seq(1, num.conceptos)
mtcars
names(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, data=mtcars)
fit
fit2 <- lm(mpg ~ factor(cyl), data=mtcars)
fit2
fit <- lm(mpg ~ factor(cyl) + wt - 1, data=mtcars)
fit
fit2 <- lm(mpg ~ factor(cyl) - 1, data=mtcars)
fit2
predict.lm(fit, newdata = data.frame(wt = c(mean(mtcars$wt))), interval = "conf")
predict.lm(fit, newdata = data.frame(wt = c(mean(mtcars$wt))), interval = "conf")
fit <- lm(mpg ~ wt, data = mtcars)
predict.lm(fit, newdata = data.frame(wt = c(mean(mtcars$wt))), interval = "conf")
predict.lm(fit, newdata = data.frame(wt = c(3), interval = "pre")
)
predict.lm(fit, newdata = data.frame(wt = c(3), interval = "pre"))
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
?mtcars
install.packages("MCDA")
library(MCDA)
install.packages("slam")
library(MCDA)
install.packages('carat')
install.packages("installr")
install.packages('devtools')
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'CarmenWaissmanGutu26')
update_packages()
library(caret)
update_packages(ggplot2)
update_packages('ggplot2')
library(caret)
library(ggplot2)
update.packages(checkBuilt = TRUE)
library(ggplot2)
library(ggplot2)
update.packages('ggplot2', checkBuilt = TRUE)
library(ggplot2)
library(caret)
version
update.packages()
update.packages()
update.packages('ggplot2', checkBuilt = TRUE)
update.packages(checkBuilt = TRUE)
library(ggplot2)
library(ggplot2)
library(ggplot2)
install.packages('ggplot2')
install.packages('carat')
install.packages('caret')
install.packages('dplyr')
install.packages('kernellab')
install.packages('kernlab')
install.packages('kappalab')
install.packages('reshape')
install.packages('reshape2')
install.packages('tydr')
install.packages('tydR')
install.packages('swirl')
library(caret)
data("faithful")
set.seed(333)
inTrain <- createDataPartition(y = faithful$waiting, p = 0.5, list = FALSE)
train.faithful <- faithful[inTrain,]
test.faithful <- faithful[-inTrain,]
head(train.faithful)
plot(train.faithful$eruptions, train.faithful$waiting)
lm1 <- lm(waiting ~ eruptions, data = train.faithful)
lines(train.faithful$eruptions, lm1$fitted.values)
library(AppliedPredictiveModeling)
install.library('AppliedPredictiveModeling')
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
View(predictors)
View(predictors)
diagnosis
adData = data.frame(diagnosis,predictors)
View(adData)
View(adData)
data(concrete)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(training)
View(training)
library(Hmisc)
install.packages('Hmisc')
library(Hmisc)
plot(training$CompressiveStrength)
cutAge <- cut2(training$Age, g=3)
plot(training$CompressiveStrength, colour=cutAge)
qplot(training$CompressiveStrength, colour=cutAge)
qplot(training$CompressiveStrength, colour=cutAge)
qplot(training$CompressiveStrength, colour=cutAge, geom = "points")
qplot(training$CompressiveStrength, colour=cutAge, geom = "point")
qplot(y=training$CompressiveStrength, colour=cutAge, geom = "point")
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutAge, geom = "point")
cutAge <- cut2(training$Age, g=5)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutAge, geom = "point")
cutAge <- cut2(training$Age, g=3)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutAge, geom = "point")
cutFly <- cut2(training$FlyAsh, g=3)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
cutFly <- cut2(training$FlyAsh, g=5)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
cutFly <- cut2(training$FlyAsh, g=5)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutAge, geom = "point")
cutFly <- cut2(training$Cement, g=5)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
cutFly <- cut2(training$Cement, g=3)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
cutFly <- cut2(training$BlastFurnaceSlag, g=3)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
cutFly <- cut2(training$Water, g=3)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
cutFly <- cut2(training$Superplasticizer, g=3)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
cutFly <- cut2(training$Superplasticizer, g=2)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
cutFly <- cut2(training$CoarseAggregate, g=3)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
cutFly <- cut2(training$FineAggregate, g=3)
qplot(x= 1:length(training$CompressiveStrength),y=training$CompressiveStrength, colour=cutFly, geom = "point")
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(training$Superplasticizer)
plot(log10(training$Superplasticizer)
)
plot(log10(training$Superplasticizer+1))
hist(log10(training$Superplasticizer))
hist(log10(training$Superplasticizer+1))
hist(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(testing)
names(testing)
grepl("IL*", names(training))
gsub("IL*", names(training))
gsub("IL*", names(training), value=TRUE)
grepl("IL*", names(training), value=TRUE)
grepl("IL*", names(training))
grep("IL*", names(training), value = TRUE)
grep(".IL*", names(training), value = TRUE)
grep("^IL*", names(training), value = TRUE)
grep("^"IL"*", names(training), value = TRUE)
grep("^[IL]*", names(training), value = TRUE)
grep("^IL*", names(training), value = TRUE)
grep("^I^L*", names(training), value = TRUE)
grep("^I+L*", names(training), value = TRUE)
grep("^I+L", names(training), value = TRUE)
grep("^IL", names(training), value = TRUE)
temp <- training[,grep("^IL", names(training), value = TRUE)]
View(temp)
View(temp)
pca.temp <- preProcess(temp, method = "pca", thresh = 0.9)
pca.temp$dim
pca.temp$rotation
tra1 <- cbind(training[,grep("^IL", names(training), value = TRUE)], training$diagnosis)
View(tra1)
tra1 <- cbind(training[,grep("^IL", names(training), value = TRUE)], diag=training$diagnosis)
View(tra1)
test1 <- cbind(testing[,grep("^IL", names(testing), value = TRUE)], diag=testing$diagnosis)
mdl1 <- train(diag ~ ., data=tra1, method = "glm")
install.packages("e107")
install.packages("e1071")
mdl1 <- train(diag ~ ., data=tra1, method = "glm")
confusionMatrix(test1$diag, predict(mdl1, test1))
mdl2 <- train(diag ~ ., data=preProcess(tra1, method = "pca", thresh = 0.8), method = "glm")
mdl2 <- train(diag ~ ., data=preProcess(diag ~ ., data=tra1, method = "pca", thresh = 0.8), method = "glm")
mdl2 <- train(preProcess(diag ~ ., data=tra1, method = "pca", thresh = 0.8), method = "glm")
mdl2 <- train(diag ~ ., data=tra1, preProcess = "pca", thresh = 0.8, method = "glm")
mdl2 <- train(diag ~ ., data=tra1, preProcess = "pca", method = "glm")
setwd("~/Documents/actualizacion/2015 Data Science/practical-ml-project")
source('~/Documents/actualizacion/2015 Data Science/practical-ml-project/intentos.R')
source('~/Documents/actualizacion/2015 Data Science/practical-ml-project/intentos.R')
source('~/Documents/actualizacion/2015 Data Science/practical-ml-project/intentos.R')
View(pml.train)
source('~/Documents/actualizacion/2015 Data Science/practical-ml-project/intentos.R')
View(pml.test)
names(pml.train)
source('~/Documents/actualizacion/2015 Data Science/practical-ml-project/intentos.R')
is.na(pml.train)
a <- is.na(pml.train)
a
sum(a)
mapply(sum, a)
?mapply
sapply(a, sum)
sapply(as.list(a), sum)
sum(a[,1])
sum(a[,2])
sum(a[,3])
sum(a[,:])
sapply(a[,:], sum)
sapply(a[,], sum)
vapply(a, sum)
table(a)
aggregate(a, sum
)
aggregate(a, FUN=sum)
highlyCorDescr <- findCorrelation(cor(pml.train), cutoff = .75)
typeof(pml.train)
apply(typeof,pml.train)
apply(pml.train, typeof)
sapply(pml.train, typeof)
View(pml.train)
View(pml.train)
typeof(pml.train[,2])
typeof(pml.train[,1])
typeof(pml.train$user_name)
pml.train$user_name[1:10]
pml.train <- pml.train[, -c('X', 'raw_timestamp_part_1', 'raw_timestamp_part_12', 'cvtd_timestamp')]
pml.train <- pml.train[, -c('X', -1:4]
pml.train <- pml.train[, -1:4]
pml.train <- pml.train[, -(1:4)]
source('~/Documents/actualizacion/2015 Data Science/practical-ml-project/intentos.R')
(1,2,3,4)
c(1,2,3,4)
pml.train <- pml.train[, -c(1,3,4,5)]
sapply(pml.train, function (l) sum(in.na(l)))
sapply(pml.train, function (l) sum(is.na(l)))
sapply(pml.train, function (l) sum(is.na(l))/19622)
?nearZeroVar
where(sapply(pml.train, function (l) sum(is.na(l))/19622) > 0.5)
find(sapply(pml.train, function (l) sum(is.na(l))/19622) > 0.5)
which(sapply(pml.train, function (l) sum(is.na(l))/19622) > 0.5)
which(sapply(pml.train, function (l) sum(is.na(l))/19622) > 0.5)
filter(sapply(pml.train, function (l) sum(is.na(l))/19622) > 0.5)
?which
filter(sapply(pml.train, function (l) sum(is.na(l))/19622 > 0.5))
which(sapply(pml.train, function (l) sum(is.na(l))/19622 > 0.5))
which(sapply(pml.train, function (l) sum(is.na(l))/19622 > 0.5), arr.ind = TRUE)
sapply(pml.train, function (l) sum(is.na(l))/19622 > 0.5)
as.list(sapply(pml.train, function (l) sum(is.na(l))/19622 > 0.5))
a <- sapply(pml.train, function (l) sum(is.na(l))/19622 < 0.5)
pml.train <- pml.train[, a]
cor(pml.train[,2:54])
pairs(pml.train)
which(cor(pml.train[,2:54])>0.7)
pml.test <- pml.test[, -c(1,3,4,5)]
pml.test <- pml.test[, a]
View(pml.test)
View(pml.test)
descrCor <-  cor(filteredDescr)
pml.train$user_name <- factor(pml.train$user_name)
pml.train$classe <- factor(pml.train$classe)
pml.test$user_name <- factor(pml.test$user_name)
des.cor <- cor(pml.train[,2:54])
highly.cor <- findCorrelation(des.cor, cutoff = .75)
highly.cor
highly.cor <- findCorrelation(des.cor, cutoff = .8)
highly.cor
highly.cor <- findCorrelation(des.cor, cutoff = .9)
highly.cor
highly.cor <- findCorrelation(des.cor, cutoff = .95)
highly.cor
nearZeroVar(pml.train)
which(in.na(pml.train))
which(is.na(pml.train))
source('~/Documents/actualizacion/2015 Data Science/practical-ml-project/intentos.R')
trans <- preProcess(pml.train1, method='pca')
pml.train2 <- predict(trans, pml.train1)
qplot(PC1, PC2, data=pml.train2, color=classe)
qplot(PC1, PC3, data=pml.train2, color=classe)
qplot(PC4, PC3, data=pml.train2, color=classe)
qplot(PC4, PC10, data=pml.train2, color=classe)
qplot(PC1, PC10, data=pml.train2, color=classe)
qplot(PC1, PC3, data=pml.train2, color=classe)
pairs(pml.train2)
pml.test2 <- predict(trans, pml.test1)
featurePlot(x = pml.train2[, 3:6],
y = iris$Species,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(4, 1),
auto.key = list(columns = 3))
featurePlot(x = pml.train2[, 3:6],
y = pml.train2$classe,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(4, 1),
auto.key = list(columns = 3))
featurePlot(x = pml.train2[, 3:6],
y = pml.train2$classe,
plot = "box",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
layout = c(2, 2),
auto.key = list(columns = 2))
transparentTheme(trans = .9)
featurePlot(x = pml.train2[, 3:6],
y = pml.train2$classe,
plot = "box")
featurePlot(x = pml.train2[, 3:6],
y = pml.train2$classe,
plot = "box",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
layout = c(2, 2))
featurePlot(x = pml.train2[, 3:6],
y = pml.train2$classe,
plot = "box",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = pml.train2[, 3:6],
y = pml.train2$classe,
plot = "box",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = pml.train2[, 3:6],
y = pml.train2$classe,
plot = "box",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = pml.train2[, 3:6],
y = pml.train2$classe,
plot = "pairs",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = pml.train2[, 3:6],
y = pml.train2$user_name,
plot = "pairs",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
d.carlitos <- pml.train2[pml.train2$user_name=="carlitos",]
featurePlot(x = d.carlitos[, 3:6],
y = d.carlitos$user_name,
plot = "pairs",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = d.carlitos[, 3:6],
y = d.carlitos$classe,
plot = "pairs",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
mdl1 <- train(classe ~ ., data=pml.train2, method='rf')
transparentTheme(trans = .9)
featurePlot(x = pml.train1[, 3:6],
y = pml.train1$classe,
plot = "pairs",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
transparentTheme(trans = .9)
featurePlot(x = pml.train1[, 3:6],
y = pml.train1$user_name,
plot = "pairs",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
featurePlot(x = pml.train1[, 3:6],
y = pml.train1$classe,
plot = "pairs",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")))
des.cor <- cor(pml.train1[,3:55])
source('~/Documents/actualizacion/2015 Data Science/practical-ml-project/intentos.R')
des.cor <- cor(pml.train1[,3:55])
des.cor <- cor(pml.train1[,2:54])
highly.cor <- findCorrelation(des.cor, cutoff = .9)
highly.cor <- findCorrelation(des.cor, cutoff = .8)
highly.cor
highly.cor <- findCorrelation(des.cor, cutoff = .9)
highly.cor
des.cor <- cor(pml.train0[,2:54])
highly.cor <- findCorrelation(des.cor, cutoff = .9)
highly.cor
highly.cor <- findCorrelation(des.cor, cutoff = .9) + 1
highly.cor
des.cor <- cor(pml.train0[,2:54])
highly.cor <- findCorrelation(des.cor, cutoff = .9) + 1
pml.test0 <- pml.test0[, highly.cor]
cen.esc <- preProcess(pml.train0, method = c("center", "scale"))
pml.train1 <- predict(cen.esc, pml.train0)
pml.test1 <- predict(cen.esc, pml.test0)
pml.train0 <- pml.train0[, highly.cor]
cen.esc <- preProcess(pml.train0, method = c("center", "scale"))
pml.train1 <- predict(cen.esc, pml.train0)
pml.test1 <- predict(cen.esc, pml.test0)
pml.test0 <- pml.test0[, -highly.cor]
source('~/Documents/actualizacion/2015 Data Science/practical-ml-project/intentos.R')
set.seed(12345)
# Split training data between training and validation
inTraining <- createDataPartition(pml.train1$classe,
p = .75, list = FALSE)
training <- pml.train1[inTraining,]
validation <- pml.train1[-inTraining,]
# Using 10-fold-cross-validation with 3 repetitions
fitControl <- trainControl(method = "repeatedcv",
number = 10, repeats = 3)
# Using a random forest model
set.seed(54321)
mdl1 <- train(Class ~ ., data = training,
method = "rf",
trControl = fitControl,
verbose = FALSE)
# Split training data between training and validation
set.seed(12345)
inTraining <- createDataPartition(pml.train1$classe,
p = .75, list = FALSE)
training <- pml.train1[inTraining,]
validation <- pml.train1[-inTraining,]
# Using 10-fold-cross-validation with 3 repetitions
fitControl <- trainControl(method = "repeatedcv",
number = 10, repeats = 3)
# Using a random forest model
set.seed(54321)
mdl1 <- train(classe ~ ., data = training,
method = "rf",
trControl = fitControl,
verbose = FALSE)
set.seed(54321)
mdl2 <- train(classe ~ ., data = training,
method = "gbm",
trControl = fitControl,
verbose = FALSE)
